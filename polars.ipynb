{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133cb4a3",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/enigma-brain/polars_workshop_2025/blob/main/polars.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013d964",
   "metadata": {},
   "source": [
    "# Polars Intro Workshop\n",
    "\n",
    "## Learning objectives\n",
    "- why is Enigma using Polars now? \n",
    "- understand advantages of Polars, basics of syntax, what's possible\n",
    "\n",
    "## Why Polars\n",
    "\n",
    "We're switching data stacks: MySQL + DataJoint -> Delta Lake tables + Polars. Several tools can analyze Delta Lake tables, but Polars offers a good balance of [performance](https://pola.rs/posts/benchmarks/) and simplicity.\n",
    "\n",
    "Orcapod uses Polars.\n",
    "\n",
    "Generally useful if you're working with 2D tables.\n",
    "\n",
    "Gaining [popularity](https://www.linkedin.com/posts/jeroenjanssens_polars-just-passed-30k-stars-on-github-congratulations-activity-7256626437082746880-fguS/).\n",
    "\n",
    "## Special features of Polars\n",
    "\n",
    "#### Performance and memory\n",
    "- Columnar architecture\n",
    "    - stores and processes data by column rather than by row\n",
    "- Parallelism by default \n",
    "- Lazy API\n",
    "    - queries aren't immediately executed; Polars optimizes the entire plan first\n",
    "- Streaming\n",
    "    - process datasets larger than available RAM by working in chunks\n",
    "\n",
    "## Core features for data manipulation\n",
    "\n",
    "Understanding these is most of the work. Extending to Lazy API and streaming is trivial.\n",
    "\n",
    "#### Data I/O\n",
    "- python objects: dict of lists, Pandas DataFrame\n",
    "- CSV, Excel, Parquet\n",
    "- Databases\n",
    "- Delta Lake tables\n",
    "- Cloud storage\n",
    "- others ([Docs](https://docs.pola.rs/user-guide/io/), [API reference](https://docs.pola.rs/api/python/dev/reference/io.html))\n",
    "\n",
    "#### Single table\n",
    "- `filter` and `select`: filter rows and select columns\n",
    "- `with_columns`: create new columns based on values in other columns\n",
    "- `group_by` and `agg`: group data and compute stats\n",
    "- `pivot` and `unpivot`: convert between long and wide format\n",
    "\n",
    "#### Multi table\n",
    "- `join` and `concat`: join and concatenation\n",
    "\n",
    "## Limitations\n",
    "- newer: smaller community, fewer tutorials\n",
    "- it's compared to Pandas, but the syntax is pretty different (although quite clear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install palmerpenguins\n",
    "import palmerpenguins as pp\n",
    "import polars as pl\n",
    "pl.Config.set_fmt_str_lengths(100) # nice for displaying longer strings and not truncate them\n",
    "\n",
    "df = pl.from_pandas(pp.load_penguins())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb4a8f",
   "metadata": {},
   "source": [
    "## Get basic understanding of data\n",
    "- `head`, `tail`\n",
    "- `glimpse`\n",
    "- `sample`\n",
    "- `schema`\n",
    "- `describe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ddf56a",
   "metadata": {},
   "source": [
    "# Data manipulation/querying\n",
    "\n",
    "Assuming we have a dataframe called `df`, using Polars generally involves the format:\n",
    "```\n",
    "df.context(expression)\n",
    "```\n",
    "where the 'context' can be one of the following:\n",
    "\n",
    "- `select` columns\n",
    "- `with_columns` to add columns to data frame\n",
    "- `filter` rows\n",
    "- `group_by` and `agg` to group rows by their values, compute statistics\n",
    "\n",
    "## `select` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a column\n",
    "df.select(\"body_mass_g\")\n",
    "\n",
    "# use pl.col to explicitly create an expression that represents a column\n",
    "df.select(pl.col(\"body_mass_g\"))\n",
    "\n",
    "# can extend pl.col to sort and do arithmetic, \n",
    "df.select(pl.col(\"body_mass_g\").sort() / 1000)\n",
    "\n",
    "# but further operations require more parentheses, e.g. renaming the column\n",
    "df.select(\n",
    "    (pl.col(\"body_mass_g\")\n",
    "     .sort() \n",
    "     / 1000)\n",
    "     .alias(\"body_mass_kg\")\n",
    ") \n",
    "\n",
    "# rename using a 'named expression'\n",
    "df.select(\n",
    "    body_mass_kg = (pl.col(\"body_mass_g\")\n",
    "     .sort() \n",
    "     / 1000)\n",
    ") \n",
    "\n",
    "# alias method nice for storing expressions in variables  \n",
    "kg_expr = ((pl.col(\"body_mass_g\").sort() / 1000).alias(\"body_mass_kg\"))\n",
    "df.select(kg_expr)\n",
    "\n",
    "# select multiple columns\n",
    "df.select(\n",
    "    (pl.col(\"species\"), pl.col(\"island\")) # or [\"species\", \"island\"]\n",
    ").unique().sort(by=\"species\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47119e",
   "metadata": {},
   "source": [
    "There are tons of methods to use within expressions (like `.sort`) that can be used in expressions. See [here](https://docs.pola.rs/api/python/stable/reference/expressions/index.html) for a full list.\n",
    "\n",
    "Problem: using `select`, create a column that computes normalized deviations from the mean body mass, and name this column \"body_mass_zscore\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expressions support broadcasting\n",
    "kg_expr = ((pl.col(\"body_mass_g\") - pl.col(\"body_mass_g\").mean()) / pl.col(\"body_mass_g\").std()).alias(\"body_mass_zscore\")\n",
    "df.select(kg_expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0eae8",
   "metadata": {},
   "source": [
    "## `with_columns` to add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two columns to add!\n",
    "kg_expr = (pl.col(\"body_mass_g\") / 1000).alias(\"body_mass_kg\")\n",
    "swim_score_expr = (pl.col(\"flipper_length_mm\") / pl.col(\"body_mass_kg\")).alias(\"swim_score\")\n",
    "\n",
    "# Polars executes expressions in the same context in parallel \n",
    "df.with_columns(\n",
    "    kg_expr,\n",
    "    swim_score_expr\n",
    ")\n",
    "\n",
    "# Columns must be creted in serial, by using `with_columns` context twice\n",
    "df = df.with_columns(\n",
    "    kg_expr,\n",
    ").with_columns(\n",
    "    swim_score_expr,\n",
    ")\n",
    "\n",
    "# note we overwrote the original dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02295d4",
   "metadata": {},
   "source": [
    "## `filter` rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"species\") == \"Gentoo\")\n",
    "\n",
    "# filter based on multiple conditions\n",
    "df.filter((pl.col(\"species\") == \"Adelie\") & (pl.col(\"island\") == \"Biscoe\"))\n",
    "\n",
    "## can use commas instead of ampersands, but not 'and'!\n",
    "df.filter(\n",
    "    (pl.col(\"species\") == \"Adelie\"), \n",
    "    (pl.col(\"island\") == \"Biscoe\"),\n",
    ")\n",
    "\n",
    "# in addition to storing expressions as variables to keep things organized, you can also define functions to create expressions\n",
    "def filter_species_island_expr(species, island):\n",
    "    return (\n",
    "        pl.col(\"species\") == species,\n",
    "        pl.col(\"island\") == island\n",
    "    )\n",
    "\n",
    "df.filter(\n",
    "    filter_species_island_expr(\"Adelie\", \"Biscoe\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa73aa4",
   "metadata": {},
   "source": [
    "Contexts can be chained together using:\n",
    "```\n",
    "df.context1(expression1).context2(expression2)\n",
    "```\n",
    "\n",
    "Problem 1: Find the Chinstrap penguin with the largest swim_score. Return just the swim_score\n",
    "\n",
    "Problem 2: Find the sex of the Chinstrap penguin with the largest swim score. Return just the sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55393564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(pl.col(\"species\") == \"Chinstrap\").select(pl.col(\"swim_score\").max().alias(\"max_swim_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01311346",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "df.select(pl.col([\"species\", \"sex\", \"swim_score\"]))\n",
    "    .filter(pl.col(\"species\") == \"Chinstrap\")\n",
    "    .sort(by=\"swim_score\", descending=True)\n",
    "    .head(1)\n",
    "    .select(pl.col(\"sex\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ffc2c",
   "metadata": {},
   "source": [
    "## `groupby` and `agg` to group rows by their values, compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"species\").agg(\n",
    "    pl.col(\"body_mass_kg\").mean(),\n",
    "    pl.col(\"swim_score\").mean(),\n",
    ").sort(by=\"species\")\n",
    "\n",
    "# group by multiple columns, rename the columns\n",
    "df.group_by([\"species\", \"sex\"]).agg(\n",
    "    pl.col(\"body_mass_kg\").mean().alias(\"mean_body_mass_g\"),\n",
    "    pl.col(\"swim_score\").mean().alias(\"mean_swim_score\"),\n",
    ").sort(by=\"species\")\n",
    "\n",
    "# drop nulls\n",
    "(\n",
    "    df\n",
    "    .drop_nulls(subset = [\"sex\"])\n",
    "    .group_by([\"species\", \"sex\"])\n",
    "    .agg(\n",
    "        pl.col(\"body_mass_kg\").mean().alias(\"mean_body_mass_kg\"),\n",
    "        pl.col(\"swim_score\").mean().alias(\"mean_swim_score\"),\n",
    "        pl.len().alias(\"count\") # count the number of rows in each group\n",
    "    )\n",
    "    .sort(by=\"species\")\n",
    ")\n",
    "\n",
    "# 'expression expansions' help remove redundant code\n",
    "(\n",
    "    df\n",
    "    .drop_nulls(subset = [\"sex\"])\n",
    "    .group_by([\"species\", \"sex\"])\n",
    "    .agg(\n",
    "        pl.col(\"body_mass_kg\", \"swim_score\").mean().name.prefix(\"mean_\"), # can also use .name.suffix(\"_mean\")\n",
    "        pl.len().alias(\"count\")\n",
    "    )\n",
    "    .sort(by=\"species\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d2301",
   "metadata": {},
   "source": [
    "Problem: use the .quantile method to compute the 0.25, 0.5, and 0.75 quantile per species. Name these columns \"q1_swim_score\", \"q2_swim_score\", etc.\n",
    "Bonus if you can avoid having .quantile in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by([\"species\"]).agg(\n",
    "        pl.col(\"swim_score\").quantile(0.25).alias(\"q1_swim_score\"),\n",
    "        pl.col(\"swim_score\").quantile(0.5).alias(\"q2_swim_score\"),\n",
    "        pl.col(\"swim_score\").quantile(0.75).alias(\"q3_swim_score\"),\n",
    "    )\n",
    "\n",
    "# more clever but less explicit\n",
    "df.group_by(\"species\").agg([\n",
    "    pl.col(\"swim_score\").quantile(q).alias(f\"q{i}_swim_score\") \n",
    "    for i, q in enumerate([0.25, 0.5, 0.75], 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d52f2",
   "metadata": {},
   "source": [
    "# Pivots: wide format <-> long format\n",
    "\n",
    "\"Wide\" tables have a column for each variable. \"Long\" tables have fewer columns, with a single column for variable type and another for the corresponding value.\n",
    "\n",
    "- `.pivot()` : long -> wide\n",
    "- `.unpivot()` : wide -> long\n",
    "\n",
    "\n",
    "\n",
    "Our dataframe is already in wide format. Let's convert it to long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb91ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go from wide to long format\n",
    "df_long = (\n",
    "            df.select(\"species\", \"island\", \"bill_length_mm\", \"bill_depth_mm\")\n",
    "            .unpivot(on=[\"bill_length_mm\", \"bill_depth_mm\"], # columns to collapse into \"variable\" column\n",
    "                    index=[\"species\", \"island\"]) # used as identifier variables\n",
    ")\n",
    "\n",
    "df_long.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408bbcf",
   "metadata": {},
   "source": [
    "Once in long format, plotting libraries like seaborn make it easy to visualize statistics with respect to these variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1092bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=df_long, x=\"species\", y=\"value\", hue=\"variable\")\n",
    "plt.title(\"Distribution of Bill Measurements by Species\")\n",
    "plt.xlabel(\"Species\")\n",
    "plt.ylabel(\"Measurement Value\")\n",
    "plt.legend(title=\"Measurement Type\")\n",
    "plt.show()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd392870",
   "metadata": {},
   "source": [
    "Going from wide to long format involves creating one-to-many relationships: the column name is now represented many times in the variable column.\n",
    "\n",
    "Alternatively, going from long to wide format involves creating many-to-one relationships. As a result, you need to also specify an 'aggregate_function' to tell Polars what to do with duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(on=\"species\", # will become the column values\n",
    "         index=\"sex\", # will become the row values\n",
    "         values=\"body_mass_kg\", # will become the values in the pivot table \n",
    "         aggregate_function=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97aa06",
   "metadata": {},
   "source": [
    "Problem: confirm with command we learned above that the max body_mass_kg for a male Adelie is that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise, confirm this for Gentoo\n",
    "df.filter(\n",
    "    (pl.col(\"species\") == \"Adelie\")\n",
    "    ).select(pl.col(\"body_mass_kg\")\n",
    "    .max()\n",
    "    )\n",
    "# or\n",
    "df.select(\n",
    "    pl.col(\"body_mass_kg\")\n",
    "    .filter(pl.col(\"species\") == \"Adelie\")\n",
    "    .max()\n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02678255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to wide format, but this fails becaue you don't know which bill length+depth go together for each individual\n",
    "df_long.pivot(on=\"variable\",\n",
    "            index=[\"species\", \"island\"],\n",
    "            values=\"value\",\n",
    "            aggregate_function=\"first\") # looking at the options available, this seems most appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo, preserving penguin ID\n",
    "# go from wide to long format\n",
    "df_long2 = (df\n",
    "            .select(\"species\", \"island\", \"bill_length_mm\", \"bill_depth_mm\")\n",
    "            .with_row_index(\"penguin_id\")\n",
    "            .unpivot([\"bill_length_mm\", \"bill_depth_mm\"],\n",
    "                index=[\"species\", \"island\", \"penguin_id\"])\n",
    ")\n",
    "df_long2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can successfully go back to wide format\n",
    "df_long2.pivot(on=\"variable\",\n",
    "            index=[\"species\", \"island\", \"penguin_id\"],\n",
    "            values=\"value\",\n",
    "            aggregate_function=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba1f6d",
   "metadata": {},
   "source": [
    "# Lazy frames\n",
    "For exploratory data analyses, use DataFrames. For performance, use LazyFrames.\n",
    "\n",
    "Syntax same as before, but results not immediately available. Need to use `.collect()`.\n",
    "\n",
    "To load in a LazyFrame, either convert an existing DataFrame or use one of the `.scan_*()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cfca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lazy = pl.LazyFrame(df)\n",
    "# df_lazy = df.lazy()\n",
    "df_lazy\n",
    "# note: methods like df_lazy.head() now behave differenlty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_expr = (pl.col(\"body_mass_g\") / 1000).alias(\"body_mass_kg\")\n",
    "gentoo_male_expr = (pl.col(\"species\") == \"Gentoo\") , (pl.col(\"sex\") == \"male\")\n",
    "\n",
    "# make lazy query that gets the body mass in kg for Gentoo males\n",
    "lazy_query = (\n",
    "    df_lazy.with_columns(kg_expr)\n",
    "    .filter(gentoo_male_expr)\n",
    "    .select(\"body_mass_kg\")\n",
    ")\n",
    "\n",
    "# returns another lazy frame\n",
    "lazy_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488701ea",
   "metadata": {},
   "source": [
    "This lazy query, which hasn't been optimized, is read from the bottom up. \n",
    "\n",
    "$\\pi$ stands for PROJECTION and refers to columns. We start with all 10 columns and end up with 1. \n",
    "\n",
    "Contexts are listed in the same order as written in our query.\n",
    "\n",
    "Let's compare this to the optimized query plan below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_query.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669bc5f",
   "metadata": {},
   "source": [
    "Polars uses predicate and projection pushdown, database optimization techniques, to make the selection of columns (projection) and the filtering of rows (predicate) as early as possible so that it only loads the data you need.\n",
    "\n",
    "You can also use `.explain()` to get a string representation of the query plan (useful if text gets truncated within graph nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b73e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_query.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a40434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a regular polars data frame, not a lazy frame\n",
    "query_results = lazy_query.collect()\n",
    "print(type(lazy_query))\n",
    "print(type(query_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d737dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6521e",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Default is to analyze all the data in memory. For streaming the data in batches, just specify as an argument in .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_query.collect(engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9662d4",
   "metadata": {},
   "source": [
    "# Misc Advanced Stuff\n",
    "## Loading multiple MySQL tables into Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6851b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install connectorx\n",
    "from urllib.parse import quote\n",
    "from getpass import getpass\n",
    "\n",
    "user = \"barnold\"\n",
    "pswd = quote(getpass('Database password: ')) # Prompt user for password; don't store in code. Use quote() to encode special characters in passwords\n",
    "server = \"at-database3.stanford.edu\"\n",
    "port = 3306\n",
    "database = \"enigma_acq\"\n",
    "tables = [\"sessions\", \"stimulation\", \"behavior_traces\"]\n",
    "\n",
    "\n",
    "uri = f\"mysql://{user}:{pswd}@{server}:{port}/{database}\" \n",
    "dfs = {}\n",
    "for table in tables:\n",
    "    query = f\"SELECT * FROM {table}\"\n",
    "    dfs[table] = pl.read_database_uri(query=query, uri=uri)\n",
    "\n",
    "dfs['sessions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f34d09",
   "metadata": {},
   "source": [
    "## conditional assignment with window function\n",
    "\n",
    "When multiple .when().then() statementes are used, Polars only considers a replacement expression that is deeper in the chain if the previous ones (predicates) all failed for that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfe139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accomplishing this in separate pieces\n",
    "\n",
    "quantiles = (\n",
    "   df.group_by([\"species\"]).agg(\n",
    "        pl.col(\"swim_score\").quantile(0.25).alias(\"q1_swim_score\"),\n",
    "        pl.col(\"swim_score\").quantile(0.5).alias(\"q2_swim_score\"),\n",
    "        pl.col(\"swim_score\").quantile(0.75).alias(\"q3_swim_score\"),\n",
    "    )\n",
    ")\n",
    "df_w_quant = df.join(quantiles, on=\"species\")\n",
    "df_w_quant = df_w_quant.with_columns(\n",
    "    pl.when(pl.col(\"swim_score\") <= pl.col(\"q1_swim_score\"))\n",
    "    .then(pl.lit(\"slow\")) # need pl.lit() otherwise Polars treats it as a column\n",
    "    .when(pl.col(\"swim_score\") <= pl.col(\"q2_swim_score\"))\n",
    "    .then(pl.lit(\"intermediate\"))\n",
    "    .when(pl.col(\"swim_score\") <= pl.col(\"q3_swim_score\"))\n",
    "    .then(pl.lit(\"fast\"))\n",
    "    .otherwise(pl.lit(\"really_fast\"))\n",
    "    .alias(\"swim_score_category\")\n",
    ").select(\n",
    "    \"species\", \"swim_score\", \"swim_score_category\"\n",
    ").sort(by=\"species\")\n",
    "\n",
    "df_w_quant.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accomplishing this in a single step, using windows functions\n",
    "df_categorized = df.with_columns(\n",
    "    pl.col(\"swim_score\").quantile(0.25).over(\"species\").alias(\"q1\"),\n",
    "    pl.col(\"swim_score\").quantile(0.5).over(\"species\").alias(\"q2\"), \n",
    "    pl.col(\"swim_score\").quantile(0.75).over(\"species\").alias(\"q3\"),\n",
    ").with_columns(\n",
    "    pl.when(pl.col(\"swim_score\") <= pl.col(\"q1\"))\n",
    "    .then(pl.lit(\"slow\"))\n",
    "    .when(pl.col(\"swim_score\") <= pl.col(\"q2\"))\n",
    "    .then(pl.lit(\"intermediate\"))\n",
    "    .when(pl.col(\"swim_score\") <= pl.col(\"q3\"))\n",
    "    .then(pl.lit(\"fast\"))\n",
    "    .otherwise(pl.lit(\"really_fast\"))\n",
    "    .alias(\"swim_score_category\")\n",
    ").drop([\"q1\", \"q2\", \"q3\"])  # Remove temporary quantile columns\n",
    "df_categorized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigma-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
